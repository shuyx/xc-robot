# **XC-ROBOT 场景测试模块设计方案**

**版本**: 1.0  
**日期**: 2025-07-18  
**来源**: 本文档基于对`fr3_hermes_testing`测试框架、`dual_arm_controller.py`、`dual_arm_integration_guide.md`及相关文档的深入分析而设计。

---

## 概述

为了系统化、可视化地验证机器人各项能力，我们设计了一个新的一级菜单——**“场景测试”**。该模块旨在提供一个统一的、交互式的界面，用于执行从单个硬件组件到复杂真实场景的全链路测试，并为未来集成视觉引导等高级功能提供框架。

## 1. 功能页面布局与细节规划

“场景测试”一级菜单下，我们规划了四个核心的二级菜单，分别对应不同层级的测试需求。

### 1.1 子菜单一：组件测试 (Component Testing)

**目标**: 对单个硬件（左臂、右臂、底盘）进行独立的、标准化的功能验证。

**页面布局**:
- **左侧面板 (测试选择区)**:
    - **设备选择下拉框**: `[选择设备: 右臂 | 左臂 | 底盘]`
    - **测试列表**: 一个根据所选设备动态加载的列表，内容来源于`fr3_hermes_testing`中的脚本。例如，选择“右臂”后，列表显示：
        - `SAT001: 连接与状态测试`
        - `SAT002: 基础运动测试`
        - `SAT003: 笛卡尔空间运动测试`
        - `SAT004: 工作空间测试`
- **中间面板 (参数与控制区)**:
    - **标题**: 显示当前选中的测试名称，如 `SAT002: 基础运动测试`。
    - **参数配置区**: (根据测试脚本动态生成) 例如，对于运动测试，会显示：
        - `速度滑块`: `速度: [ 20 ] %`
        - `安全距离输入框`: `双臂安全距离 (mm): [ 200 ]`
    - **控制按钮**: 一个醒目的 **[▶️ 开始测试]** 按钮，旁边是 **[⏹️ 紧急停止]** 按钮。
- **右侧面板 (结果显示区)**:
    - **实时日志**: 一个只读文本区域，实时滚动显示测试脚本的输出日志。
    - **状态概览**: 几个关键的状态标签，如 `测试状态: [待命 | 运行中 | 通过 | 失败]`, `已用时: [15.2s]`。

### 1.2 子菜单二：集成测试 (Integration Testing)

**目标**: 验证多个组件协同工作的能力，特别是双臂的协调与安全避障。

**页面布局**:
- **左侧面板 (测试选择与监控)**:
    - **测试列表**: 显示所有集成测试脚本，如：
        - `DAT001: 双臂同步连接测试`
        - `DAT002: 双臂安全距离测试`
        - `CAI-001: 底盘-机械臂联动测试`
    - **实时监控区**: 显示关键的协调状态数据。
        - `左臂状态: [已连接 | 运动中]`
        - `右臂状态: [已连接 | 运动中]`
        - `双臂末端距离: [ 450.8 mm ]` (距离过近时会高亮红色)
- **右侧主面板 (3D可视化与日志)**:
    - **3D安全视图**: 一个简化的3D“火柴人”视图，实时渲染双臂的姿态和相对位置。当双臂距离接近安全阈值时，连杆模型会变色告警。该视图基于`dual_arm_safety_model.py`进行可视化。
    - **控制与日志区**: 位于3D视图下方，包含 **[▶️ 开始测试]** / **[⏹️ 紧急停止]** 按钮和实时日志窗口。

### 1.3 子菜单三：视觉引导测试 (Vision-Guided Testing)

**目标**: 测试视觉系统（ToF相机、2D相机）的数据采集、处理及引导能力。

**页面布局**:
- **主视图 (分屏显示)**:
    - **左侧：相机画面**: 
        - `相机选择`: `[Gemini 335 (RGB) | Gemini 335 (Depth)]`
        - `视频流窗口`: 实时显示选中相机的视频流。深度图会以伪彩形式展示。
        - `控制按钮`: `[暂停/播放]`, `[截图]`
    - **右侧：数据与控制**:
        - `视觉任务控制`: 一组按钮用于触发不同的AI视觉任务。
            - `[侦测物体]`
            - `[识别二维码]`
            - `[计算抓取点]`
        - `结果输出窗口`: 显示视觉任务的结果，如：
          ```json
          {
            "object_detected": "cup",
            "position_3d": [0.5, 0.2, 0.8],
            "grasp_pose": [ ... ]
          }
          ```
        - `引导操作按钮`: `[移动机械臂到抓取点]` (将视觉结果转化为机器人动作)。

### 1.4 子菜单四：端到端场景 (End-to-End Scenarios)

**目标**: 执行一个完整的、接近真实应用的工作流程，验证系统的综合能力。

**页面布局**:
- **顶部面板 (场景选择与控制)**:
    - **场景选择下拉框**: `[选择场景: 1. 桌面物品抓取与分类 | 2. 协作搬运 | 3. 巡检与读表]`
    - **控制按钮**: **[▶️ 执行场景]**, **[⏸️ 暂停]**, **[⏹️ 停止]**
- **主面板 (任务状态与监控)**:
    - **任务步骤列表**: 实时高亮显示当前正在执行的任务步骤。
        - `1. 底盘移动到工作台A (进行中...)`
        - `2. 扫描桌面物品`
        - `3. 左臂抓取杯子`
        - `4. 右臂抓取书本`
        - `...`
    - **多视图监控**: 一个可以切换的监控区域。
        - `标签1: 3D视图` (显示机器人整体运动)
        - `标签2: 相机视图` (显示机器人第一视角)
        - `标签3: 详细日志` (显示`integrated_controller.py`的详细输出)

---

## 2. 技术路线与实现方案

### 2.1 后端实现 (Python)

**核心**: 扩展 `gui/web_bridge.py` 中的 `WebBridge` 类，添加新的 `@pyqtSlot` 来连接前端UI和后端测试逻辑。

1.  **测试脚本管理与执行**: 
    - **`discover_tests(category)`**: 新增一个方法，用于扫描 `fr3_hermes_testing` 目录，根据脚本元信息（或文件名约定）返回指定类别的测试列表 (JSON格式)。
    - **`run_test(script_name, params)`**: 这个方法将是核心。它会使用Python的 `subprocess` 模块在一个新的进程中执行指定的测试脚本。它会捕获该子进程的 `stdout` 和 `stderr`，并通过Qt信号实时地将日志流式传输到前端。

2.  **实时数据流**: 
    - **`get_integration_status()`**: 定时被前端调用（如每秒2次）。它会访问双臂控制器，获取双臂的关节角度和末端距离，并返回JSON数据用于更新“集成测试”页面的3D视图和监控面板。
    - **`get_camera_frame(camera_id)`**: 定时被前端调用（如每秒10次）。它会从视觉控制模块捕获一帧图像，编码为Base64字符串，并返回给前端显示。这可以模拟出视频流的效果。

3.  **视觉与场景任务**: 
    - **`trigger_vision_task(task_name)`**: 调用视觉处理模块的相应函数（如物体检测），并异步地返回结果。
    - **`run_e2e_scenario(scenario_name)`**: 调用 `main_control/integrated_controller.py` 中的高级任务序列。

### 2.2 前端实现 (HTML/CSS/JavaScript)

**核心**: 大量使用JavaScript进行动态UI构建和异步数据交互。

1.  **动态UI生成**: 
    - 页面加载时，调用 `bridge.discover_tests()` 获取测试列表，并动态生成“组件测试”和“集成测试”的菜单。
    - 当用户选择一个测试时，根据需要动态创建参数配置控件（滑块、输入框等）。

2.  **异步通信与数据绑定**: 
    - **日志流**: 监听后端 `WebBridge` 发出的日志信号 (`log_signal.connect(...)`)，并将收到的日志行追加到日志窗口。
    - **实时监控**: 使用 `setInterval` 定时调用后端的 `get_integration_status()` 和 `get_camera_frame()`，并在回调函数中更新UI元素（如3D视图、视频`<img>`标签的`src`属性）。

3.  **3D可视化**: 
    - 对于“集成测试”中的3D安全视图，推荐使用轻量级的JavaScript 3D库，如 **`Three.js`**。
    - JS代码会根据从 `get_integration_status()` 获取的关节角度，通过正向运动学计算出“火柴人”模型的节点位置，并更新渲染场景。

### 2.3 测试脚本适配

为了更好地与UI集成，`fr3_hermes_testing` 中的测试脚本需要进行微小调整：
- **结构化输出**: 除了人类可读的日志，脚本应向 `stdout` 输出JSON格式的结构化信息，如 `{"type": "status", "message": "通过"}` 或 `{"type": "progress", "value": 50}`。这使得前端可以更容易地解析测试状态并更新UI。
- **参数化**: 脚本应能通过命令行参数接收配置（如速度、安全距离），以便UI可以传递用户设置。

### 2.4 总体技术流程（以“组件测试”为例）

1.  **前端**: 用户在UI上选择“右臂”和“SAT002: 基础运动测试”，调整速度为25%，点击“开始测试”。
2.  **前端JS**: 调用 `bridge.run_test('SAT002.py', {'arm': 'right', 'speed': 25})`。
3.  **后端Bridge**: 接收到调用，启动一个子进程 `python fr3_hermes_testing/SAT002.py --arm right --speed 25`。
4.  **后端Bridge**: 捕获 `SAT002.py` 的标准输出流。
5.  **测试脚本**: 执行测试，并 `print()` 结构化的JSON日志。
6.  **后端Bridge**: 每当从子进程读到一行输出，就通过Qt信号 `log_signal.emit(line)` 发送给前端。
7.  **前端JS**: 监听 `log_signal`，接收到日志行后，解析JSON并更新日志窗口和状态标签。
8.  **后端Bridge**: 当子进程结束后，发送一个最终状态信号，前端将“运行中”状态改为“通过”或“失败”。
